{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38a592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 08-03 16:23:50 [__init__.py:235] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.7.11: Fast Qwen3 patching. Transformers: 4.54.1. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.635 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4dfe06bfad479f8deb5e31cbed1d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    # model_name = \"unsloth/Qwen3-8B-Base-unsloth-bnb-4bit\",\n",
    "    # model_name=\"unsloth/gemma-3-12b-pt\",\n",
    "    # model_name=\"unsloth/gemma-3-4b-pt\",\n",
    "    max_seq_length = 8192, # Choose any for long context!\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1924f4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(2, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (1): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (2): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (3-5): 3 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (6): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (7-35): 29 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85643657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2308, 7414]\n"
     ]
    }
   ],
   "source": [
    "# save the lm_head for yes and no\n",
    "index = [tokenizer.encode(\" No\")[0], tokenizer.encode(\" Yes\")[0]]\n",
    "print(index)\n",
    "torch.save(model.lm_head.weight[index], './Model/Gwen8B_lm_head.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8c317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc07711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5934a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m loss = loss_fn(logits[:\u001b[32m2\u001b[39m], labels) \u001b[38;5;66;03m# first 2 tokens are used for training, (N, C), (N,)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m vi_index.shape[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     prob = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from utility import build_dataloader\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Data/Data1/train.csv\")\n",
    "dataloader = build_dataloader(df, tokenizer)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "prob_list = defaultdict(list)\n",
    "for i, (row_id, input_ids, vi_index, labels) in enumerate(dataloader):\n",
    "    row_id = int(row_id)\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        input_ids, vi_index, labels = input_ids.to('cuda'), vi_index.to('cuda'), labels.to('cuda')\n",
    "        output = model.model(input_ids)\n",
    "        logits = output.last_hidden_state[0, vi_index] @ lm_head_weight # (# of Violation, 4096) @ (4096, 2) -> (# of Violation, 2)\n",
    "        loss = loss_fn(logits[:2], labels) # first 2 tokens are used for training, (N, C), (N,)\n",
    "        loss.backward()\n",
    "        if vi_index.shape[0] == 3:\n",
    "            prob = torch.softmax(logits[2], dim=0)[1].item()\n",
    "            prob_list[row_id].append(prob)\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            clip_grad_value_(trainable_params,clip)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afef7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.softmax(logits[2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757c43cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92578125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea09b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(logits[:2], labels) # first 2 tokens are used for training, (N, C), (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f60298",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m torch.softmax(\u001b[43mlogits\u001b[49m[\u001b[32m2\u001b[39m], dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "torch.softmax(logits[2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b397aaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7414, device='cuda:0'), tensor(2308, device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0, 67], input_ids[0, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af1042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac0ac0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2610,   525,  2661,   264,  3980,   389, 42174,    13,  4615,  3383,\n",
       "           374,   311, 48129,   421,   432, 50313,   279,  2661,  5912,   624,\n",
       "          3136, 36933,    25,   435, 21284, 53344,   198, 11337,    25,  2308,\n",
       "         46323,    25, 81667,    11, 44780,  7746,    11,  6975, 91104, 12876,\n",
       "            11,   323, 34282,  2213,   525,   537,  5420,   624, 10677,    25,\n",
       "          3908, 38788,  3330,   369,   697, 22951,   633,   752,  1588,   366,\n",
       "          3144,  1670,   757, 61419,   397, 74971,    25,  7414,   198, 10677,\n",
       "            25,  5145,  1588, 55460,  1784,  3144, 83338,   905,   397, 74971,\n",
       "            25,  2308,   198, 10677,    25,  5692,   594,   847, 44780,  2656,\n",
       "            11,  9339,   323,  4669, 35575,   366,  3144,    62,  2136,  7031,\n",
       "           908,  1327,   802, 24822,   905,   397, 74971,    25]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids#[0, vi_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98525193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5ae817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32.2500, 34.2500],\n",
       "        [35.7500, 37.0000]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795b004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8125, device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8741cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae8585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6931)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a043564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 132])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206192e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
