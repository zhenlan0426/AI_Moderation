{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a592b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1624556268.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel_name = \"unsloth/Qwen3-8B-Base-unsloth-bnb-4bit\"\u001b[39m\n                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    # model_name = \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    model_name = \"unsloth/Qwen3-8B-Base-unsloth-bnb-4bit\",\n",
    "    # model_name=\"unsloth/gemma-3-12b-pt\",\n",
    "    # model_name=\"unsloth/gemma-3-4b-pt\",\n",
    "    max_seq_length = 8192, # Choose any for long context!\n",
    "    load_in_4bit = True,\n",
    "    # resize_model_vocab=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1924f4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096, padding_idx=151654)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (3): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (4): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (5): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (6): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (7-33): 27 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (34): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "      (35): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85643657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2308, 7414]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the lm_head for yes and no\n",
    "index = [tokenizer.encode(\" No\")[0], tokenizer.encode(\" Yes\")[0]]\n",
    "print(index)\n",
    "model.lm_head.weight[index]\n",
    "custom_embedding = nn.Embedding(2, 4096)\n",
    "custom_embedding.weight.data = model.lm_head.weight.data[index]\n",
    "torch.save(custom_embedding.state_dict(), './Model/Gwen8B_lm_head.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc07711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b23773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "tokenizer.encode(\n",
      "    text: Union[str, list[str], list[int]],\n",
      "    text_pair: Union[str, list[str], list[int], NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    add_special_tokens: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    padding: Union[bool, str, transformers.utils.generic.PaddingStrategy] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    truncation: Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    max_length: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    stride: int = \u001b[32m0\u001b[39m,\n",
      "    padding_side: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    return_tensors: Union[str, transformers.utils.generic.TensorType, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **kwargs,\n",
      ") -> list[int]\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\n",
      "\n",
      "Same as doing `self.convert_tokens_to_ids(self.tokenize(text))`.\n",
      "\n",
      "Args:\n",
      "    text (`str`, `list[str]` or `list[int]`):\n",
      "        The first sequence to be encoded. This can be a string, a list of strings (tokenized string using the\n",
      "        `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\n",
      "        method).\n",
      "    text_pair (`str`, `list[str]` or `list[int]`, *optional*):\n",
      "        Optional second sequence to be encoded. This can be a string, a list of strings (tokenized string using\n",
      "        the `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\n",
      "        method).\n",
      "\n",
      "    add_special_tokens (`bool`, *optional*, defaults to `True`):\n",
      "        Whether or not to add special tokens when encoding the sequences. This will use the underlying\n",
      "        `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines which tokens are\n",
      "        automatically added to the input ids. This is useful if you want to add `bos` or `eos` tokens\n",
      "        automatically.\n",
      "    padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `False`):\n",
      "        Activates and controls padding. Accepts the following values:\n",
      "\n",
      "        - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
      "          sequence is provided).\n",
      "        - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
      "          acceptable input length for the model if that argument is not provided.\n",
      "        - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n",
      "          lengths).\n",
      "    truncation (`bool`, `str` or [`~tokenization_utils_base.TruncationStrategy`], *optional*, defaults to `False`):\n",
      "        Activates and controls truncation. Accepts the following values:\n",
      "\n",
      "        - `True` or `'longest_first'`: Truncate to a maximum length specified with the argument `max_length` or\n",
      "          to the maximum acceptable input length for the model if that argument is not provided. This will\n",
      "          truncate token by token, removing a token from the longest sequence in the pair if a pair of\n",
      "          sequences (or a batch of pairs) is provided.\n",
      "        - `'only_first'`: Truncate to a maximum length specified with the argument `max_length` or to the\n",
      "          maximum acceptable input length for the model if that argument is not provided. This will only\n",
      "          truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
      "        - `'only_second'`: Truncate to a maximum length specified with the argument `max_length` or to the\n",
      "          maximum acceptable input length for the model if that argument is not provided. This will only\n",
      "          truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
      "        - `False` or `'do_not_truncate'` (default): No truncation (i.e., can output batch with sequence lengths\n",
      "          greater than the model maximum admissible input size).\n",
      "    max_length (`int`, *optional*):\n",
      "        Controls the maximum length to use by one of the truncation/padding parameters.\n",
      "\n",
      "        If left unset or set to `None`, this will use the predefined model maximum length if a maximum length\n",
      "        is required by one of the truncation/padding parameters. If the model has no specific maximum input\n",
      "        length (like XLNet) truncation/padding to a maximum length will be deactivated.\n",
      "    stride (`int`, *optional*, defaults to 0):\n",
      "        If set to a number along with `max_length`, the overflowing tokens returned when\n",
      "        `return_overflowing_tokens=True` will contain some tokens from the end of the truncated sequence\n",
      "        returned to provide some overlap between truncated and overflowing sequences. The value of this\n",
      "        argument defines the number of overlapping tokens.\n",
      "    is_split_into_words (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not the input is already pre-tokenized (e.g., split into words). If set to `True`, the\n",
      "        tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)\n",
      "        which it will tokenize. This is useful for NER or token classification.\n",
      "    pad_to_multiple_of (`int`, *optional*):\n",
      "        If set will pad the sequence to a multiple of the provided value. Requires `padding` to be activated.\n",
      "        This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability\n",
      "        `>= 7.5` (Volta).\n",
      "    padding_side (`str`, *optional*):\n",
      "        The side on which the model should have padding applied. Should be selected between ['right', 'left'].\n",
      "        Default value is picked from the class attribute of the same name.\n",
      "    return_tensors (`str` or [`~utils.TensorType`], *optional*):\n",
      "        If set, will return tensors instead of list of python integers. Acceptable values are:\n",
      "\n",
      "        - `'tf'`: Return TensorFlow `tf.constant` objects.\n",
      "        - `'pt'`: Return PyTorch `torch.Tensor` objects.\n",
      "        - `'np'`: Return Numpy `np.ndarray` objects.\n",
      "\n",
      "    **kwargs: Passed along to the `.tokenize()` method.\n",
      "\n",
      "Returns:\n",
      "    `list[int]`, `torch.Tensor`, `tf.Tensor` or `np.ndarray`: The tokenized ids of the text.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "    @add_end_docstrings(\n",
      "        ENCODE_KWARGS_DOCSTRING,\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m            **kwargs: Passed along to the `.tokenize()` method.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m,\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns:\u001b[39m\n",
      "\u001b[33m            `list[int]`, `torch.Tensor`, `tf.Tensor` or `np.ndarray`: The tokenized ids of the text.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m,\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m encode(\n",
      "        self,\n",
      "        text: Union[TextInput, PreTokenizedInput, EncodedInput],\n",
      "        text_pair: Optional[Union[TextInput, PreTokenizedInput, EncodedInput]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        add_special_tokens: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        padding: Union[bool, str, PaddingStrategy] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        truncation: Union[bool, str, TruncationStrategy, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_length: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        stride: int = \u001b[32m0\u001b[39m,\n",
      "        padding_side: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        return_tensors: Optional[Union[str, TensorType]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ) -> list[int]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39m\n",
      "\n",
      "\u001b[33m        Same as doing `self.convert_tokens_to_ids(self.tokenize(text))`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Args:\u001b[39m\n",
      "\u001b[33m            text (`str`, `list[str]` or `list[int]`):\u001b[39m\n",
      "\u001b[33m                The first sequence to be encoded. This can be a string, a list of strings (tokenized string using the\u001b[39m\n",
      "\u001b[33m                `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\u001b[39m\n",
      "\u001b[33m                method).\u001b[39m\n",
      "\u001b[33m            text_pair (`str`, `list[str]` or `list[int]`, *optional*):\u001b[39m\n",
      "\u001b[33m                Optional second sequence to be encoded. This can be a string, a list of strings (tokenized string using\u001b[39m\n",
      "\u001b[33m                the `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\u001b[39m\n",
      "\u001b[33m                method).\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        encoded_inputs = self.encode_plus(\n",
      "            text,\n",
      "            text_pair=text_pair,\n",
      "            add_special_tokens=add_special_tokens,\n",
      "            padding=padding,\n",
      "            truncation=truncation,\n",
      "            max_length=max_length,\n",
      "            stride=stride,\n",
      "            padding_side=padding_side,\n",
      "            return_tensors=return_tensors,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m encoded_inputs[\u001b[33m\"input_ids\"\u001b[39m]\n",
      "\u001b[31mFile:\u001b[39m      ~/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "tokenizer.encode??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f7ebe71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74971, 25]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\n",
    "            \"Violation:\", add_special_tokens=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8012d946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2610,   525,  2661,   264,  3980,   389, 42174,    13,  4615,  3383,\n",
       "           374,   311, 48129,   421,   432, 50313,   279,  2661,  5912,   624,\n",
       "          3136, 36933,    25,   435, 12697,   198, 11337,    25,  1273,   198,\n",
       "         10677,    25,  1273,   198, 74971,    25,  1273,   198, 10677,    25,\n",
       "          1273,   198, 74971,    25,  1273,   198]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit = \"test\"\n",
    "rule = \"test\"\n",
    "comment1 = \"test\"\n",
    "label1 = \"test\"\n",
    "\n",
    "\n",
    "tokenizer.encode(\n",
    "            \"You are given a comment on reddit. Your task is to classify if it violates the given rule.\\n\"\n",
    "            f\"Subreddit: r/{subreddit}\\n\"\n",
    "            f\"Rule: {rule}\\n\"\n",
    "            f\"Comment: {comment1}\\n\"\n",
    "            f\"Violation: {label1}\\n\"\n",
    "            f\"Comment: {comment1}\\n\"\n",
    "            f\"Violation: {label1}\\n\"\n",
    "            , add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bf06bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from utility import build_dataloader\n",
    "\n",
    "# After making changes to the utility module\n",
    "import utility\n",
    "importlib.reload(utility)\n",
    "from utility import build_dataloader  # Get the updated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import build_dataloader\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Data/Data1/train.csv\")\n",
    "dataloader = build_dataloader(df, tokenizer)\n",
    "for row_id, input_ids, vi_index, labels in dataloader:\n",
    "    row_id = int(row_id)\n",
    "    input_ids, vi_index, labels = input_ids.to('cuda'), vi_index.to('cuda'), labels.to('cuda')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043564d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95341650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(row_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24231f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 79, 121, 165])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cea98a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25, 25, 25])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0, vi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5937ca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "645ae8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2610,   525,  2661,   264,  3980,   389, 42174,    13,  4615,  3383,\n",
       "           374,   311, 48129,   421,   432, 50313,   279,  2661,  5912,   624,\n",
       "          3136, 36933,    25,   435,  2687, 96188, 60975,   198, 11337,    25,\n",
       "          2308, 46323,    25, 81667,    11, 44780,  7746,    11,  6975, 91104,\n",
       "         12876,    11,   323, 34282,  2213,   525,   537,  5420,   624, 10677,\n",
       "            25, 27553, 10546,  2611,    11,   600,  1184,  5274,  1431,   421,\n",
       "           575,  1366,  3736,   847, 20036,  6548,   600,  3783,   498,  1588,\n",
       "           366,  3144, 32005,   454,    16,    17,   905,   397, 74971,    25,\n",
       "          7414,   198, 10677,    25,  8030,  9203,   481,   508, 22574,  9203,\n",
       "          9533,    27,  3144, 12673,    17,    19, 83560,   905,    29,   760,\n",
       "            58,  9951,    45,  9203,   220,    17,  9533,    27,  3144, 12673,\n",
       "            17,    19, 83560,   905,   397, 18370,   481,  2806, 66265,   198,\n",
       "         74971,    25,  2308,   198, 10677,    25,  8030,  9203,   549,    58,\n",
       "          4477, 34496,  5095,   220,    19,   356,  1285,   828,  5863,  9533,\n",
       "            27,  3144,   643,   287,   307,   359,   372, 97646,    29,   760,\n",
       "          4710, 10531, 54061,   320, 72997,   481,   393,  8825,   687,   425,\n",
       "         54331,     8, 14080,   198, 74971,    25]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
